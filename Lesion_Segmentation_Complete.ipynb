{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cryanwashere/cams_stuff/blob/main/Lesion_Segmentation_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm9aEYjU68Ke"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fesj0a_rhX-6"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "import tensorflow.keras.layers as tfl\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxz6UAMI69zx"
      },
      "source": [
        "rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vRrnGRUiROE"
      },
      "source": [
        "image_path = 'drive/MyDrive/Data/ISIC2018_Task1-2_Training_Input'\n",
        "mask_path = 'drive/MyDrive/Data/ISIC2018_Task1_Training_GroundTruth'\n",
        "image_dir = os.listdir(image_path)\n",
        "mask_dir = os.listdir(mask_path)\n",
        "image_dir.sort()\n",
        "mask_dir.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJj-kDLV0ymP"
      },
      "source": [
        "train_number = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlDEbstG8a6e",
        "outputId": "8808078a-a7bc-4c35-d0f4-c9176a4f5f1a"
      },
      "source": [
        "images = []\n",
        "count = 0\n",
        "for i in image_dir:\n",
        "  if i != 'ATTRIBUTION.txt':\n",
        "    if count > train_number:\n",
        "      break\n",
        "    count+=1\n",
        "    image = cv2.imread(os.path.join(image_path, i))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (128,128))\n",
        "    images.append(image)\n",
        "    clear_output(wait=True)\n",
        "    print(count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP2-qYJ696E4"
      },
      "source": [
        "masks = []\n",
        "count = 0\n",
        "for i in mask_dir:\n",
        "  if i != 'ATTRIBUTION.txt':\n",
        "    if count > train_number:\n",
        "      break\n",
        "    count+=1\n",
        "    mask = cv2.imread(os.path.join(mask_path, i))\n",
        "    mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "    mask = cv2.resize(mask, (104,104))\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    masks.append(mask)\n",
        "    clear_output(wait=True)\n",
        "    print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndXUTE3SC8v5"
      },
      "source": [
        "for i in range(len(images)):\n",
        "  images[i] = images[i]/255\n",
        "  masks[i] = masks[i]/255\n",
        "\n",
        "images=np.array(images)\n",
        "masks=np.array(masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uofLNqpFAujX"
      },
      "source": [
        "input_shape = ( 128, 128, 3)\n",
        "input = tfl.Input(shape = (input_shape))\n",
        "c0 = tfl.Conv2D(64, 3, activation = 'relu')(input)\n",
        "c1 = tfl.Conv2D(64, 3, activation = 'relu')(c0)\n",
        "m1 = tfl.MaxPool2D(pool_size = (2,2), strides = (2,2))(c1)\n",
        "c2 = tfl.Conv2D(128, 3, activation = 'relu')(m1)\n",
        "c3 = tfl.Conv2D(128, 3, activation = 'relu')(c2)\n",
        "m2 = tfl.MaxPool2D(pool_size = (2,2), strides = (2,2))(c3)\n",
        "c4 = tfl.Conv2D(256, 3, activation = 'relu')(m2)\n",
        "c5 = tfl.Conv2D(256, 3, activation = 'relu')(c4)\n",
        "m3 = tfl.MaxPool2D(pool_size = (2,2), strides = (2,2))(c5)\n",
        "c6 = tfl.Conv2D(512, 3, activation = 'relu')(m3)\n",
        "c7 = tfl.Conv2D(512, 3, activation = 'relu')(c6)\n",
        "t1 = tfl.Conv2DTranspose(256, 2, strides = (3,3), activation = 'relu')(c7)\n",
        "crop1 = tfl.Cropping2D(cropping = ((1,0), (1,0)))(c5)\n",
        "concat1 = tfl.Concatenate(axis = -1)([t1, crop1])\n",
        "c8 = tfl.Conv2D(256, 3, activation = 'relu')(concat1)\n",
        "c9 = tfl.Conv2D(256, 3, activation = 'relu')(c8)\n",
        "t2 = tfl.Conv2DTranspose(128, 2, strides = (2,2), activation = 'relu')(c9)\n",
        "crop2 = tfl.Cropping2D(cropping = ((9,9), (9,9)))(c3)\n",
        "concat2 = tfl.Concatenate(axis = -1)([t2, crop2])\n",
        "c10 = tfl.Conv2D(128, 3, activation = 'relu')(concat2)\n",
        "c11= tfl.Conv2D(128, 3, activation = 'relu')(c10)\n",
        "t3 = tfl.Conv2DTranspose(64, 2, strides = (3,3), activation = 'relu')(c11)\n",
        "crop3 = tfl.Cropping2D(cropping = ((8,8), (8,8)))(c1)\n",
        "concat3 = tfl.Concatenate(axis = -1)([t3, crop3])\n",
        "c12= tfl.Conv2D(64, 3, activation = 'relu')(concat3)\n",
        "output = tfl.Conv2D(1, 3)(c12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj71IFztAvaR"
      },
      "source": [
        "model = tf.keras.Model(inputs = input, outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNUPHzBdDmWB"
      },
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ds9aCDG60VH"
      },
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WF2BlENhFJo0",
        "outputId": "55c20b3f-8fc8-499f-9db5-3a359f95d3a2"
      },
      "source": [
        "history = model.fit(images, masks, epochs = 10, verbose=1, callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 563s 17s/step - loss: 0.4572 - accuracy: 0.7526\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 556s 17s/step - loss: 0.3748 - accuracy: 0.8268\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 556s 17s/step - loss: 0.3520 - accuracy: 0.8411\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 557s 17s/step - loss: 0.3413 - accuracy: 0.8466\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 556s 17s/step - loss: 0.3441 - accuracy: 0.8491\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 557s 17s/step - loss: 0.3283 - accuracy: 0.8552\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 557s 17s/step - loss: 0.4113 - accuracy: 0.8248\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 557s 17s/step - loss: 0.3395 - accuracy: 0.8509\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 557s 17s/step - loss: 0.3337 - accuracy: 0.8550\n",
            "Epoch 10/10\n",
            "20/32 [=================>............] - ETA: 3:50 - loss: 0.3410 - accuracy: 0.8531"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU7uY0nj7FLs"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgmBwlEjocQT"
      },
      "source": [
        "model.save('drive/MyDrive/Data/LesionSegmentationModel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRmkRbgtuakx"
      },
      "source": [
        "def clean_mask(image, precision):\n",
        "  mask=model.predict(image[tf.newaxis,...])\n",
        "  mask=np.expand_dims(tf.squeeze(mask),axis=-1)\n",
        "  mask=cv2.resize(mask,(128,128))\n",
        "  mask=np.expand_dims(mask,axis=-1)\n",
        "\n",
        "  clean_mask=[]\n",
        "  for i in mask:\n",
        "    row=[]\n",
        "    for j in i:\n",
        "      if j>precision:\n",
        "        row.append(1)\n",
        "      else:\n",
        "        row.append(0)\n",
        "    clean_mask.append(row)\n",
        "  clean_mask=np.expand_dims(clean_mask,axis=-1)\n",
        "  return clean_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6EZRKjBPUkQ"
      },
      "source": [
        "plt.imshow(tf.squeeze(clean_mask(images[23], 0.1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS-0E_3yPYnK"
      },
      "source": [
        "plt.imshow(images[23])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogZTPE-hdhc8"
      },
      "source": [
        "[1,0.5,0.7]\n",
        "[0.1,0.4,0.7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x5CivM6Plp8"
      },
      "source": [
        "rand=random.randint(0,500)\n",
        "image=images[rand]\n",
        "mask=clean_mask(image, 0.3)\n",
        "cleaned_image=[]\n",
        "\n",
        "for i in range(128):\n",
        "  row=[]\n",
        "  for j in range(128):\n",
        "    if mask[i][j]==1:\n",
        "      row.append(image[i][j])\n",
        "    else:\n",
        "      row.append([0.1,0.4,0.7])\n",
        "  cleaned_image.append(row)\n",
        "\n",
        "\n",
        "\n",
        "print(np.shape(cleaned_image))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(cleaned_image)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnZJgepbB6iO"
      },
      "source": [
        "sample_path='drive/MyDrive/Data/leedsbutterfly/images/0010001.png'\n",
        "sample_image=cv2.imread(sample_path)\n",
        "sample_image=cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "sample_image=cv2.resize(sample_image,(128,128))\n",
        "print(np.shape(sample_image))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(sample_image)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(tf.squeeze(model.predict(sample_image[tf.newaxis,...])))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}