{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lesion Classification Complete","provenance":[],"mount_file_id":"1mdh1WSEsPWpAJ6aV_eUlc3-jS634fHsS","authorship_tag":"ABX9TyOTyjG3lh+tCQq/1yJ2w5FG"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"YwGrjCdYVzYz"},"source":["import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","import cv2\n","from IPython.display import clear_output\n","import random\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yKvixkhkh-Z"},"source":["train_number=3000"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbCdEJWnb0Bh","executionInfo":{"elapsed":132296,"status":"ok","timestamp":1628703019121,"user":{"displayName":"Cameron Ryan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNr_H0g8zQlgXoY1oG7PrKPlrOzfDM8C7ZGlyU5g=s64","userId":"06821684098009557896"},"user_tz":240},"outputId":"67bf02ca-5ae5-4f46-ba60-018d410fe688"},"source":["image_path='drive/MyDrive/Data/ISIC2018_Task3_Training_Input'\n","image_dir=os.listdir(image_path)\n","image_dir.sort()\n","label_path='drive/MyDrive/Data/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv'\n","label_data=pd.read_csv(label_path)\n","label_data=label_data.to_numpy()\n","\n","labels=[]\n","count=0\n","for i in label_data:\n","  if count>train_number:\n","    break\n","  else:\n","    count+=1\n","    array=[]\n","    for j in i:\n","        array.append(j)\n","    array.remove(array[0])\n","    labels.append(array)\n","    clear_output(wait=True)\n","    print(\"Labels: \",count)\n","\n","images=[]\n","count=0\n","for i in image_dir:\n","  if count>train_number:\n","    break\n","  else:\n","    if i!='ATTRIBUTION.txt':\n","      count+=1\n","      image=cv2.imread(os.path.join(image_path,i))\n","      image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n","      image=cv2.resize(image,(256,256))\n","      images.append(image)\n","      clear_output(wait=True)\n","      print(\"Images: \",count)\n","\n","count=0\n","for i in range(len(images)):\n","  count+=1\n","  images[i]=images[i]/255\n","  clear_output(wait=True)\n","  print(\"Normalizing Images...\",count)\n","images=np.array(images)\n","labels=np.array(labels)\n","\n","clear_output(wait=True)\n","print(\"Finished, \",count)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Finished,  3001\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nz3JbVGgWnNt"},"source":[" def create_conv_model(): \n","  model = models.Sequential()\n","  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","  model.add(layers.Flatten())\n","  model.add(layers.Dense(64, activation='relu'))\n","  model.add(layers.Dense(7))\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEAJpWWwmW5X"},"source":["basic_model=create_conv_model()\n","\n","basic_model.compile(\n","    optimizer='adam',\n","    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n","    metrics=['accuracy']\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"wr-rxSfNm1Wg","outputId":"307cf14e-992a-4974-d241-0d66fc139c1f"},"source":["basic_model.fit(images,labels,epochs=20,verbose=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/42\n","94/94 [==============================] - 261s 3s/step - loss: 0.3342 - accuracy: 0.6671\n","Epoch 2/42\n","94/94 [==============================] - 262s 3s/step - loss: 0.2624 - accuracy: 0.6828\n","Epoch 3/42\n","94/94 [==============================] - 258s 3s/step - loss: 0.2619 - accuracy: 0.6828\n","Epoch 4/42\n","94/94 [==============================] - 255s 3s/step - loss: 0.2599 - accuracy: 0.6828\n","Epoch 5/42\n","94/94 [==============================] - 261s 3s/step - loss: 0.2576 - accuracy: 0.6828\n","Epoch 6/42\n","94/94 [==============================] - 258s 3s/step - loss: 0.2581 - accuracy: 0.6838\n","Epoch 7/42\n","94/94 [==============================] - 256s 3s/step - loss: 0.2577 - accuracy: 0.6834\n","Epoch 8/42\n","94/94 [==============================] - 252s 3s/step - loss: 0.2553 - accuracy: 0.6831\n","Epoch 9/42\n","94/94 [==============================] - 261s 3s/step - loss: 0.2540 - accuracy: 0.6841\n","Epoch 10/42\n","94/94 [==============================] - 260s 3s/step - loss: 0.2533 - accuracy: 0.6851\n","Epoch 11/42\n","94/94 [==============================] - 254s 3s/step - loss: 0.2560 - accuracy: 0.6854\n","Epoch 12/42\n","94/94 [==============================] - 253s 3s/step - loss: 0.2554 - accuracy: 0.6841\n","Epoch 13/42\n","94/94 [==============================] - 252s 3s/step - loss: 0.2534 - accuracy: 0.6851\n","Epoch 14/42\n","94/94 [==============================] - 251s 3s/step - loss: 0.2583 - accuracy: 0.6868\n","Epoch 15/42\n","94/94 [==============================] - 250s 3s/step - loss: 0.2570 - accuracy: 0.6824\n","Epoch 16/42\n","94/94 [==============================] - 250s 3s/step - loss: 0.2543 - accuracy: 0.6841\n","Epoch 17/42\n","94/94 [==============================] - 255s 3s/step - loss: 0.2540 - accuracy: 0.6831\n","Epoch 18/42\n","94/94 [==============================] - 251s 3s/step - loss: 0.2604 - accuracy: 0.6841\n","Epoch 19/42\n","94/94 [==============================] - 251s 3s/step - loss: 0.2566 - accuracy: 0.6834\n","Epoch 20/42\n","94/94 [==============================] - 255s 3s/step - loss: 0.2587 - accuracy: 0.6841\n","Epoch 21/42\n","94/94 [==============================] - 250s 3s/step - loss: 0.2563 - accuracy: 0.6848\n","Epoch 22/42\n","94/94 [==============================] - 247s 3s/step - loss: 0.2549 - accuracy: 0.6838\n","Epoch 23/42\n","94/94 [==============================] - 247s 3s/step - loss: 0.2555 - accuracy: 0.6848\n","Epoch 24/42\n","94/94 [==============================] - 249s 3s/step - loss: 0.2543 - accuracy: 0.6838\n","Epoch 25/42\n","94/94 [==============================] - 249s 3s/step - loss: 0.2526 - accuracy: 0.6848\n","Epoch 26/42\n","94/94 [==============================] - 246s 3s/step - loss: 0.2525 - accuracy: 0.6854\n","Epoch 27/42\n","94/94 [==============================] - 253s 3s/step - loss: 0.2560 - accuracy: 0.6848\n","Epoch 28/42\n","94/94 [==============================] - 247s 3s/step - loss: 0.2534 - accuracy: 0.6864\n","Epoch 29/42\n","38/94 [===========>..................] - ETA: 2:28 - loss: 0.2488 - accuracy: 0.6965"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NnSLLeVTAlO5"},"source":["basic_model.save('drive/MyDrive/Data/BasicConvolutionalModel.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LC0KVfcnKpZ"},"source":["def create_discriminator_model():\n","  model = models.Sequential()\n","  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 512, 3)))\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","  model.add(layers.MaxPooling2D((2, 2)))\n","  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","  model.add(layers.Flatten())\n","  model.add(layers.Dense(64, activation='relu'))\n","  model.add(layers.Dense(1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDMfiCsrn0tZ"},"source":["models=[]\n","for i in range(7):\n","  model=create_discriminator_model()\n","  models.append(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bkBt6le574n3"},"source":["def create_discriminator_label(label_1,label_2):\n","  for i in range(len(label_1)):\n","    if label_1[i]==1.0:\n","      num=i\n","      break\n","  if label_2[num]==1.0:\n","    label=1\n","  else:\n","    label=0\n","  return label\n","\n","def create_discriminator_data(image_1,image_2,label_1,label_2):\n","  label=create_discriminator_label(label_1,label_2)\n","\n","  new_image=[]\n","  for i in range(256):\n","    row=[]\n","    for j in range(256):\n","      row.append(image_1[i][j])\n","    for j in range(256):\n","      row.append(image_2[i][j])\n","    new_image.append(row)\n","  \n","  return new_image, label\n","\n","def create_discriminator_dataset(number_samples):\n","  discriminator_images=[]\n","  discriminator_labels=[]\n","\n","  for i in range(number_samples):\n","    rand_1=random.randint(0,(number_samples-1))\n","    rand_2=random.randint(0,(number_samples-1))\n","    image,label=create_discriminator_data(images[rand_1],images[rand_2],labels[rand_1],labels[rand_2])\n","    discriminator_images.append(image)\n","    discriminator_labels.append(label)\n","\n","  return discriminator_images, discriminator_labels"],"execution_count":null,"outputs":[]}]}